"""
P√°gina de Machine Learning
==========================

M√≥dulo para an√°lisis predictivo y modelado avanzado.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from components.data_loader import DataLoader
from config.settings import THEME_COLORS, PLOTLY_CONFIG


def render_ml(data_loader: DataLoader, filters: dict):
    """
    Renderiza la p√°gina de Machine Learning.
    
    Args:
        data_loader: Instancia del cargador de datos
        filters: Diccionario con filtros del usuario
    """
    
    # Header
    st.markdown("""
    <h1 class="main-title">ü§ñ Machine Learning</h1>
    <p class="subtitle">
        An√°lisis Predictivo y Modelado Avanzado
    </p>
    """, unsafe_allow_html=True)
    
    # Info sobre disponibilidad de datos
    st.info("""
üìä **Estado de Datos para Machine Learning**

Esta secci√≥n aplica t√©cnicas de ML sobre los datos de migraci√≥n cient√≠fica disponibles.

**‚úÖ Datos disponibles:**
- **Flujos migratorios:** 4,249 rutas bilaterales entre pa√≠ses
- **Variables:** Inmigraci√≥n, emigraci√≥n, saldo neto, volumen total
- **Cobertura:** Investigadores con PhD 2000-2016

**‚ö†Ô∏è Limitaciones actuales:**
- Los **indicadores econ√≥micos** (PIB, I+D) del World Bank requieren procesamiento adicional para ser integrados en estos an√°lisis.
- Por ahora, los modelos se enfocan en **patrones migratorios puros** sin variables econ√≥micas.

**üéØ An√°lisis disponibles:** Clustering de pa√≠ses por similitud migratoria, an√°lisis de correlaciones entre variables migratorias, y estad√≠sticas descriptivas avanzadas.
    """)
    
    # =================================================================
    # TABS DE AN√ÅLISIS ML
    # =================================================================
    
    st.markdown('<div class="section-header">üî¨ An√°lisis de Machine Learning</div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs([
        "üìä Correlaciones",
        "üéØ Clustering",
        "ÔøΩ Distribuciones"
    ])
    
    with tab1:
        render_correlation_demo(data_loader)
    
    with tab2:
        render_clustering_demo(data_loader)
    
    with tab3:
        render_prediction_demo(data_loader)
    
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # =================================================================
    # FRAMEWORK FUTURO
    # =================================================================
    
    st.markdown('<div class="section-header">üöÄ Framework para Desarrollo Futuro</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üìà Series Temporales Avanzadas
        
        **Modelos a implementar:**
        - **ARIMA/SARIMA**: Capturar tendencias y estacionalidad
        - **Prophet (Facebook)**: Predicciones robustas con eventos especiales
        - **LSTM (Deep Learning)**: Redes neuronales para patrones complejos
        
        **Aplicaciones:**
        - Predicci√≥n de flujos 2020-2030
        - Identificaci√≥n de puntos de inflexi√≥n
        - An√°lisis de impacto de eventos (COVID-19, Brexit, pol√≠ticas)
        - Escenarios probabil√≠sticos (mejor/peor caso)
        
        ---
        
        ### üß† Modelos Ensemble Avanzados
        
        **Random Forest y Gradient Boosting:**
        - **XGBoost/LightGBM**: Predicci√≥n de corredores emergentes
        - **Feature importance**: Variables m√°s influyentes
        - **SHAP values**: Explicabilidad de predicciones
        
        **Casos de uso:**
        - Clasificar pa√≠ses en riesgo de brain drain
        - Predecir √©xito de pol√≠ticas de retorno
        - Identificar factores cr√≠ticos por regi√≥n
        """)
    
    with col2:
        st.markdown("""
        ### üî¨ Clustering Avanzado
        
        **T√©cnicas adicionales:**
        - **DBSCAN**: Detecci√≥n de outliers y clusters de forma arbitraria
        - **Hierarchical Clustering**: Dendrogramas para jerarqu√≠as
        - **t-SNE/UMAP**: Visualizaci√≥n de alta dimensionalidad
        - **Gaussian Mixture Models**: Clustering probabil√≠stico
        
        **An√°lisis:**
        - Segmentaci√≥n por disciplina cient√≠fica
        - Evoluci√≥n temporal de clusters
        - Identificaci√≥n de pa√≠ses en transici√≥n
        
        ---
        
        ### üéØ Inferencia Causal
        
        **M√©todos causales:**
        - **Propensity Score Matching**: Efecto de pol√≠ticas espec√≠ficas
        - **Difference-in-Differences**: Impacto de intervenciones
        - **Synthetic Control**: Comparaci√≥n con pa√≠ses contrafactuales
        - **Instrumental Variables**: Variables instrumentales
        
        **Preguntas a responder:**
        - ¬øIncrementar I+D causa atracci√≥n de talento?
        - ¬øEfecto real del Brexit en flujos UK?
        - ¬øROI de programas de repatriaci√≥n?
        """)

    
    # =================================================================
    # ROADMAP
    # =================================================================
    
    st.markdown('<div class="section-header">üó∫Ô∏è Roadmap de Desarrollo</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### Fases de Implementaci√≥n
    
    #### **Fase 1: Fundamentos (Q1 2026)** ‚úÖ Pr√≥ximo
    - [ ] Ingenier√≠a de caracter√≠sticas avanzada
    - [ ] Matriz de correlaci√≥n interactiva
    - [ ] An√°lisis de componentes principales (PCA)
    - [ ] Clustering K-Means b√°sico
    
    #### **Fase 2: Modelos Predictivos (Q2 2026)**
    - [ ] Series temporales con Prophet
    - [ ] Regresi√≥n m√∫ltiple con validaci√≥n cruzada
    - [ ] Escenarios "what-if" interactivos
    - [ ] Dashboard de predicciones
    
    #### **Fase 3: ML Avanzado (Q3 2026)**
    - [ ] Random Forest y XGBoost
    - [ ] Redes neuronales (TensorFlow/PyTorch)
    - [ ] AutoML con TPOT o AutoKeras
    - [ ] Explicabilidad con SHAP
    
    #### **Fase 4: Inferencia Causal (Q4 2026)**
    - [ ] Propensity Score Matching
    - [ ] Difference-in-Differences
    - [ ] Synthetic Control Methods
    - [ ] Reportes de impacto de pol√≠ticas
    """)
    
    # Feedback
    st.markdown("<br>", unsafe_allow_html=True)
    
    with st.expander("üí¨ Sugerencias para esta secci√≥n"):
        st.markdown("""
        ### ¬øQu√© an√°lisis ML te gustar√≠a ver?
        
        D√©janos saber qu√© modelos o an√°lisis ser√≠an m√°s √∫tiles:
        - Predicciones espec√≠ficas
        - Nuevas variables a considerar
        - Tipos de visualizaciones
        - Casos de uso particulares
        
        **Contacto:** [Tu email o GitHub]
        """)


# =============================================================================
# DEMOS INTERACTIVAS
# =============================================================================

def render_correlation_demo(data_loader: DataLoader):
    """An√°lisis de correlaci√≥n entre variables migratorias."""
    
    st.markdown("### üìä An√°lisis de Correlaciones Migratorias")
    
    st.markdown("""
    Explora las relaciones entre variables migratorias: inmigraci√≥n, emigraci√≥n, 
    saldo neto y flujo total de investigadores entre pa√≠ses.
    """)
    
    # Cargar datos
    df_flows = data_loader.load_flows()
    
    if df_flows.empty:
        st.warning("No hay datos disponibles.")
        return
    
    # Usar datos de migraci√≥n agregados por pa√≠s
    correlation_data = data_loader.compute_net_migration(df_flows)
    
    # Seleccionar columnas num√©ricas para correlaci√≥n
    numeric_cols = correlation_data.select_dtypes(include=[np.number]).columns.tolist()
    
    # Eliminar columnas con demasiados NaN
    valid_cols = [col for col in numeric_cols 
                  if correlation_data[col].notna().sum() > len(correlation_data) * 0.3]
    
    if len(valid_cols) < 2:
        st.warning(f"‚ö†Ô∏è Datos insuficientes para an√°lisis de correlaci√≥n. Solo {len(valid_cols)} columna(s) num√©ricas v√°lidas encontradas.")
        st.info(f"Columnas disponibles: {', '.join(correlation_data.columns.tolist()[:10])}")
        
        # Mostrar al menos las estad√≠sticas b√°sicas de migraci√≥n
        if not correlation_data.empty:
            st.markdown("### üìä Estad√≠sticas B√°sicas de Migraci√≥n")
            basic_cols = ['immigration', 'emigration', 'net_balance', 'total_flow']
            available_basic = [col for col in basic_cols if col in correlation_data.columns]
            
            if available_basic:
                st.dataframe(
                    correlation_data[available_basic].describe(),
                    use_container_width=True
                )
        return
    
    # Calcular matriz de correlaci√≥n
    corr_matrix = correlation_data[valid_cols].corr()
    
    # Crear heatmap
    fig = px.imshow(
        corr_matrix,
        text_auto='.2f',
        aspect='auto',
        color_continuous_scale='RdBu_r',
        zmin=-1,
        zmax=1,
        title='Matriz de Correlaci√≥n de Pearson',
        labels=dict(color="Correlaci√≥n")
    )
    
    fig.update_layout(
        height=600,
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig, use_container_width=True, config=PLOTLY_CONFIG)
    
    # Encontrar correlaciones m√°s fuertes
    st.markdown("### üîç Correlaciones M√°s Fuertes")
    
    # Crear dataframe de correlaciones
    corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_pairs.append({
                'Variable 1': corr_matrix.columns[i],
                'Variable 2': corr_matrix.columns[j],
                'Correlaci√≥n': corr_matrix.iloc[i, j]
            })
    
    corr_df = pd.DataFrame(corr_pairs)
    corr_df['Abs_Corr'] = corr_df['Correlaci√≥n'].abs()
    corr_df = corr_df.sort_values('Abs_Corr', ascending=False)
    
    # Mostrar top correlaciones
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üî¥ Correlaciones Positivas M√°s Fuertes:**")
        top_positive = corr_df[corr_df['Correlaci√≥n'] > 0].head(5)
        for _, row in top_positive.iterrows():
            st.markdown(f"- **{row['Variable 1']}** ‚Üî **{row['Variable 2']}**: {row['Correlaci√≥n']:.3f}")
    
    with col2:
        st.markdown("**üîµ Correlaciones Negativas M√°s Fuertes:**")
        top_negative = corr_df[corr_df['Correlaci√≥n'] < 0].head(5)
        for _, row in top_negative.iterrows():
            st.markdown(f"- **{row['Variable 1']}** ‚Üî **{row['Variable 2']}**: {row['Correlaci√≥n']:.3f}")
    
    # Interpretaci√≥n
    st.markdown("""
    <div class="alert-info">
        <p><strong>üí° Interpretaci√≥n:</strong></p>
        <ul>
            <li><strong>+1.0:</strong> Correlaci√≥n positiva perfecta</li>
            <li><strong>+0.7 a +1.0:</strong> Correlaci√≥n positiva fuerte</li>
            <li><strong>+0.3 a +0.7:</strong> Correlaci√≥n positiva moderada</li>
            <li><strong>-0.3 a +0.3:</strong> Correlaci√≥n d√©bil</li>
            <li><strong>-0.7 a -0.3:</strong> Correlaci√≥n negativa moderada</li>
            <li><strong>-1.0 a -0.7:</strong> Correlaci√≥n negativa fuerte</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


def render_clustering_demo(data_loader: DataLoader):
    """Demo de clustering de pa√≠ses por caracter√≠sticas migratorias."""
    
    st.markdown("### üéØ Clustering de Pa√≠ses")
    
    st.markdown("""
    Agrupa pa√≠ses con patrones migratorios similares usando **K-Means** y **PCA** 
    para visualizaci√≥n en 2D.
    """)
    
    # Cargar datos
    df_flows = data_loader.load_flows()
    if df_flows.empty:
        st.warning("No hay datos disponibles para clustering.")
        return
    
    # Calcular caracter√≠sticas por pa√≠s
    country_features = data_loader.compute_net_migration(df_flows)
    
    # Preparar features para clustering (solo variables migratorias)
    feature_cols = ['immigration', 'emigration', 'net_balance', 'total_flow']
    
    # Filtrar pa√≠ses con datos completos
    clustering_data = country_features[['country'] + feature_cols].dropna()
    
    if len(clustering_data) < 10:
        st.warning("Datos insuficientes para clustering (m√≠nimo 10 pa√≠ses con datos completos).")
        return
    
    # N√∫mero de clusters
    col1, col2 = st.columns([1, 3])
    with col1:
        n_clusters = st.slider("N√∫mero de Clusters", min_value=2, max_value=7, value=4)
    
    # Normalizar datos
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(clustering_data[feature_cols])
    
    # Aplicar K-Means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clustering_data['cluster'] = kmeans.fit_predict(X_scaled)
    
    # PCA para visualizaci√≥n 2D
    pca = PCA(n_components=2, random_state=42)
    X_pca = pca.fit_transform(X_scaled)
    clustering_data['PC1'] = X_pca[:, 0]
    clustering_data['PC2'] = X_pca[:, 1]
    
    # Visualizaci√≥n
    fig = px.scatter(
        clustering_data,
        x='PC1',
        y='PC2',
        color='cluster',
        hover_name='country',
        hover_data=feature_cols,
        title=f'Clustering de Pa√≠ses en {n_clusters} Grupos (K-Means + PCA)',
        labels={
            'PC1': f'Componente Principal 1 ({pca.explained_variance_ratio_[0]:.1%} varianza)',
            'PC2': f'Componente Principal 2 ({pca.explained_variance_ratio_[1]:.1%} varianza)',
            'cluster': 'Cluster'
        },
        color_continuous_scale='Viridis'
    )
    
    fig.update_traces(marker=dict(size=12, line=dict(width=0.5, color='white')))
    fig.update_layout(
        height=600,
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig, use_container_width=True, config=PLOTLY_CONFIG)
    
    # Interpretaci√≥n de clusters
    st.markdown("### üìã Perfil de cada Cluster")
    
    for cluster_id in range(n_clusters):
        cluster_countries = clustering_data[clustering_data['cluster'] == cluster_id]
        
        with st.expander(f"**Cluster {cluster_id}** ({len(cluster_countries)} pa√≠ses)"):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Top 5 pa√≠ses del cluster
                st.markdown("**Pa√≠ses principales:**")
                top_countries = cluster_countries.nlargest(5, 'total_flow')['country'].tolist()
                st.write(", ".join(top_countries))
            
            with col2:
                # Caracter√≠sticas promedio
                st.markdown("**Promedios:**")
                avg_net = cluster_countries['net_balance'].mean()
                st.metric("Saldo Neto", f"{avg_net:,.0f}", 
                         delta="Atractor" if avg_net > 0 else "Exportador")
            
            # Estad√≠sticas del cluster
            st.markdown("**Caracter√≠sticas:**")
            stats_df = cluster_countries[feature_cols].describe().loc[['mean', '50%']].T
            stats_df.columns = ['Media', 'Mediana']
            st.dataframe(stats_df.style.format("{:,.0f}"), use_container_width=True)


def render_prediction_demo(data_loader: DataLoader):
    """An√°lisis estad√≠stico avanzado de patrones migratorios."""
    
    st.markdown("### ÔøΩ An√°lisis Estad√≠stico Avanzado")
    
    st.markdown("""
    An√°lisis de distribuciones y patrones estad√≠sticos en los flujos migratorios 
    de investigadores cient√≠ficos.
    """)
    
    # Cargar datos
    df_flows = data_loader.load_flows()
    
    if df_flows.empty:
        st.warning("No hay datos disponibles.")
        return
    
    # Preparar datos
    net_migration = data_loader.compute_net_migration(df_flows)
    
    # An√°lisis de distribuciones
    st.markdown("### üìä Distribuci√≥n de Saldos Migratorios")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Pa√≠ses Atractores", 
                 len(net_migration[net_migration['net_balance'] > 0]),
                 help="Pa√≠ses con balance neto positivo")
    with col2:
        st.metric("Pa√≠ses Exportadores", 
                 len(net_migration[net_migration['net_balance'] < 0]),
                 help="Pa√≠ses con balance neto negativo")
    with col3:
        st.metric("Total Pa√≠ses", len(net_migration))
    
    # Histograma de saldos
    fig_hist = px.histogram(
        net_migration,
        x='net_balance',
        nbins=50,
        title='Distribuci√≥n de Saldos Migratorios por Pa√≠s',
        labels={'net_balance': 'Saldo Migratorio Neto', 'count': 'Frecuencia'},
        color_discrete_sequence=[THEME_COLORS['primary']]
    )
    
    fig_hist.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="Balance = 0")
    fig_hist.update_layout(
        height=400,
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig_hist, use_container_width=True, config=PLOTLY_CONFIG)
    
    # Top atractores y exportadores
    st.markdown("### üèÜ Rankings")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Top 10 Atractores:**")
        top_attractors = net_migration.nlargest(10, 'net_balance')[['country', 'net_balance', 'immigration']]
        top_attractors.columns = ['Pa√≠s', 'Saldo Neto', 'Inmigraci√≥n']
        st.dataframe(top_attractors.style.format({'Saldo Neto': '{:,.0f}', 'Inmigraci√≥n': '{:,.0f}'}), 
                    hide_index=True, use_container_width=True)
    
    with col2:
        st.markdown("**Top 10 Exportadores:**")
        top_exporters = net_migration.nsmallest(10, 'net_balance')[['country', 'net_balance', 'emigration']]
        top_exporters.columns = ['Pa√≠s', 'Saldo Neto', 'Emigraci√≥n']
        st.dataframe(top_exporters.style.format({'Saldo Neto': '{:,.0f}', 'Emigraci√≥n': '{:,.0f}'}), 
                    hide_index=True, use_container_width=True)
    
    # An√°lisis de regresi√≥n simple
    st.markdown("### üìà Regresi√≥n: Inmigraci√≥n vs. Emigraci√≥n")
    
    st.markdown("""
    Analiza la relaci√≥n entre inmigraci√≥n y emigraci√≥n para identificar patrones 
    (ej: pa√≠ses que atraen mucho tambi√©n pierden mucho, o viceversa).
    """)
    
    # Scatter plot
    fig_scatter = px.scatter(
        net_migration,
        x='emigration',
        y='immigration',
        size='total_flow',
        hover_name='country',
        title='Relaci√≥n entre Emigraci√≥n e Inmigraci√≥n',
        labels={
            'emigration': 'Emigraci√≥n (investigadores)',
            'immigration': 'Inmigraci√≥n (investigadores)',
            'total_flow': 'Flujo Total'
        },
        trendline="ols",
        color='net_balance',
        color_continuous_scale='RdYlGn'
    )
    
    fig_scatter.update_layout(
        height=500,
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig_scatter, use_container_width=True, config=PLOTLY_CONFIG)
    
    # Correlaci√≥n
    corr = net_migration[['immigration', 'emigration']].corr().iloc[0, 1]
    
    st.markdown(f"""
    <div class="alert-info">
        <h4>ÔøΩ Correlaci√≥n: {corr:.3f}</h4>
        <p>{'Existe una correlaci√≥n positiva moderada' if corr > 0.5 else 'La correlaci√≥n es d√©bil'} 
        entre inmigraci√≥n y emigraci√≥n. Esto sugiere que pa√≠ses con alta movilidad tienden a 
        tener flujos en ambas direcciones.</p>
    </div>
    """, unsafe_allow_html=True)


# =============================================================================
# RECURSOS ADICIONALES
# =============================================================================

def render_ml_resources():
    """Muestra recursos para aprender ML aplicado a ciencia de datos."""
    
    st.markdown("""
    ### üìö Recursos para Machine Learning
    
    **Librer√≠as Python:**
    - [scikit-learn](https://scikit-learn.org/): ML cl√°sico
    - [TensorFlow](https://www.tensorflow.org/): Deep Learning
    - [Prophet](https://facebook.github.io/prophet/): Series temporales
    - [XGBoost](https://xgboost.readthedocs.io/): Gradient Boosting
    - [SHAP](https://shap.readthedocs.io/): Explicabilidad de modelos
    
    **Tutoriales:**
    - [Machine Learning Mastery](https://machinelearningmastery.com/)
    - [Kaggle Learn](https://www.kaggle.com/learn)
    - [Fast.ai](https://www.fast.ai/)
    """)
